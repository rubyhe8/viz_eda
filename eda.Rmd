---
title: "eda"
author: "ruby"
date: "2025-10-02"
output: html_document
---
## exploratory data analysis 

load library 
```{r}
library(tidyverse)
library(p8105.datasets)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

import weather data
```{r}
data("weather_df")

weather_df = 
  weather_df |> 
  mutate(month = floor_date(date, unit = "month"))
```

make plots 

```{r}
weather_df |> 
  ggplot(aes(x=prcp)) +
  geom_histogram()

```


Check on extreme values 

```{r}
weather_df |> 
  filter(prcp > 1000)
```

look at data again. 
```{r}
weather_df |> 
  filter(tmax >= 20, tmax <= 30) |> 
  ggplot(aes(x = tmin, y = tmax, color = name, shape = name)) +
  geom_point()
```

## add groups 

```{r}
weather_df |> 
  group_by(name, month)
```

group and count things 
```{r}
weather_df |> 
  group_by(name) |> 
  summarize(
    n = n()
  )
```

```{r}
weather_df |> 
  group_by(month) |> 
  summarize(
    n = n()
  )
```

```{r}
weather_df |> 
  group_by(month) |> 
  summarize(
    n = n_distinct(date)
  )
```

you can count directly - group by name and count up the number of observations in each 
```{r}
weather_df |> 
  count(name)
```

computing a mean tmax across all weather stations in each month
```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    median_tmin = median(tmin, na.rm = TRUE),
    sd_prcp = sd(prcp, na.rm = TRUE)
  )
```

this is still a dataframe!

```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) |> 
  ggplot(aes(x = month, y = mean_tmax, color = name))+
  geom_point() + geom_line()
```

sometimes format results more nicely 

```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE)
  ) |> 
  pivot_wider(
    names_from = name, 
    values_from = mean_tmax
  ) |> 
  knitr::kable(digits = 2)
```

## mutate with groups 

```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    center_tmax = tmax - mean_tmax
  ) |> 
  ggplot(aes(x = date, y = center_tmax, color = name)) +
  geom_point()
```

look for cold days. 

```{r}
weather_df |> 
  group_by(name, month) |> 
  mutate(temp_rank = min_rank(tmax)) |> 
  filter(temp_rank < 2)
```

in central park in jan of 2021, the tmax is 4.4 -> 14th coldest day in jan 2021 in central park 

what about lags? (is todays tmax related to yesterdays?)
-> the order of the dataset matters in this case 

```{r}
weather_df |> 
  group_by(name) |> 
  mutate(lagged_tmax = lag(tmax))
```

use the variables you create 

```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    temp_change = tmax-lag(tmax)
  ) |> 
  summarize(
    sd_tmax_change = sd(temp_change, na.rm = TRUE),
    tmax_change_max = max(temp_change, na.rm = TRUE)
  )
```

to see on which day is temp change the largest in each location 
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    temp_change = tmax-lag(tmax), 
    change_rank = min_rank(desc(temp_change))
  ) |> 
  filter(change_rank < 2)
```

## revisit pulse dataset 
```{r}
pulse_df = 
  haven::read_sas("data/public_pulse_data.sas7bdat") |> 
  janitor::clean_names() |> 
  pivot_longer(
    bdi_score_bl:bdi_score_12m,
    names_to = "visit",
    names_prefix = "bdi_score_",
    values_to = "bdi"
  ) |> 
  mutate(visit = fct_inorder(visit))

pulse_df |> 
  ggplot(aes(x = visit, y = bdi)) +
  geom_boxplot()

pulse_df |> 
  group_by(visit) |> 
  summarize(
    median_bdi = median(bdi, na.rm = TRUE), 
    mean_bdi = mean(bdi, na.rm = TRUE)
  ) |> 
  knitr::kable(digits = 2)
```

